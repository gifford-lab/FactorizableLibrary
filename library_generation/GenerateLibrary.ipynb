{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, dilation):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation)\n",
    "        self.conv1_bn = nn.BatchNorm1d(channels)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation)\n",
    "        self.conv2_bn = nn.BatchNorm1d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = F.relu( self.conv1_bn( self.conv1(x) ) )\n",
    "        return self.conv2_bn( self.conv2(x1) ) + x\n",
    "\n",
    "class EmbedderNet(nn.Module):\n",
    "    def __init__(self, length, channels, outchannels):\n",
    "        super(EmbedderNet, self).__init__()\n",
    "        self.length = length\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2, 2, ceil_mode = True)\n",
    "        self.conv = nn.Conv1d(40, channels, 1, 1, 0)\n",
    "        self.conv_bn = nn.BatchNorm1d(channels)\n",
    "        \n",
    "        self.block1 = ResBlock(channels, 1)\n",
    "        self.block2 = ResBlock(channels, 1)\n",
    "        self.block3 = ResBlock(channels, 1)\n",
    "        self.block4 = ResBlock(channels, 1)\n",
    "        self.block5 = ResBlock(channels, 1)\n",
    "        \n",
    "        self.embed_1 = nn.Linear( int( channels*math.ceil(math.ceil(self.length/2)/2) ) , 128)\n",
    "        self.embed_2 = nn.Linear(128, outchannels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        x = F.relu( self.conv_bn( self.conv(x) ) )\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool( self.block4(x) )\n",
    "        x = self.pool( self.block5(x) ).view(batchsize,-1)\n",
    "        return self.embed_2( F.relu( self.embed_1(x) ) )\n",
    "    \n",
    "class Predictor_Dot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predictor_Dot, self).__init__()\n",
    "        self.embedPrefix = EmbedderNet(10, 64, 16)\n",
    "        self.embedSuffix = EmbedderNet(10, 64, 16)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        prefix = x[:,:,:10]\n",
    "        suffix = x[:,:,10:]\n",
    "        return torch.sum(self.embedPrefix(prefix) * self.embedSuffix(suffix), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetEnsemble(nn.Module):\n",
    "    def __init__(self, lst):\n",
    "        super(NetEnsemble, self).__init__()\n",
    "        self.nets = nn.ModuleList(lst)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.stack([net(x) for net in self.nets]).permute((1,0,2))\n",
    "\n",
    "class Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combine, self).__init__()\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        return torch.einsum(\"nij,nij->n\",x1,x2)\n",
    "        \n",
    "    def getPrefix(self, x1, x2):\n",
    "        return torch.einsum(\"nij,ij->n\",x1,x2)\n",
    "    \n",
    "    def getSuffix(self, x1, x2):\n",
    "        return torch.einsum(\"ij,nij->n\",x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add optimizer with documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
